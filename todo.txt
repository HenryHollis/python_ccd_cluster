WHAT IVE LEARNED/COMMON ERRORS
1. Make sure your in a Conda env that matches the architecture of your machine
2. Make try removing the builds in /build and running python setup.py install
3. Make sure '-g' is in the extra_compile_args in setup.py:
	extra_compile_args=['-std=c++11', '-g']
4. Now that I want numpy functionality in c++, make sure:
    a. To include numpy.get_include() in include_dirs arg of setup.py
    B. That gives the full path of header <numpy/arrayobject.h>, which you need to include in cpp files
    C. Make sure you use import_array() in PyInit__c_leiden.
    D. Solved maddening segfault from docs: https://docs.scipy.org/doc/numpy-1.10.1/reference/c-api.array.html#miscellaneous
       Basically, import_array() is "static" and has problems if you want to include numpy functionality across multiple cpp
       files. The solution is to define a compiler directive #define PY_ARRAY_UNIQUE_SYMBOL cool_ARRAY_API in pynterface.h and 
       #define NO_IMPORT_ARRAY in python_partition_interface.h. 
5. By making the ccd_diff operation commutative, I have removed the infinite loop.


TODO:
-Try to make this scale better, cannot do 10,000 cells at the moment.
- Remove the -O0 flag in compiler arguments in setup.py
3. Change the CCD_comm_size. We don't want to calculate ccd(single node) or CCD(community with single group).
   It is unclear if we want X number of individuals per group in a community before we calc CCD.
   Also, should there be two separate params for these thresholds? For example thresh1 = number of nodes in a community
   before CCD can be calculated. thresh2 = number of groups in a community before ccd can be calculated.

- Double check that ccdCache is working and provides any benefit- IT IS AND IT DOES
5. Update quality()
6. Update docstring of ccdModularityVertexPartition in VertexPartition.py

